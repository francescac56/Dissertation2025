{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TG1MBJZsTVZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcdfb104-c29d-41ff-bb53-44d71d1c1b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import KFold\n",
        "import torch.nn.functional as F\n",
        "from itertools import product\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import csv\n",
        "from pathlib import Path\n",
        "import os\n",
        "import subprocess\n",
        "import random\n",
        "from Bio import AlignIO, Phylo, SeqIO\n",
        "from Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from Bio.Align import MultipleSeqAlignment\n",
        "from pathlib import Path\n",
        "import time\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.pipeline          import Pipeline\n",
        "from sklearn.preprocessing     import StandardScaler\n",
        "from sklearn.linear_model      import LogisticRegression\n",
        "from sklearn.ensemble          import RandomForestClassifier, StackingClassifier\n",
        "from xgboost                   import XGBClassifier\n",
        "from sklearn.model_selection   import StratifiedKFold, GridSearchCV\n",
        "from sklearn.decomposition     import PCA\n",
        "from sklearn.metrics           import (\n",
        "    balanced_accuracy_score,\n",
        "    roc_auc_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    auc,\n",
        "    f1_score\n",
        ")"
      ],
      "metadata": {
        "id": "gf_eZpvBTdIR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base = Path('/content/drive/MyDrive')\n",
        "print(\"Top-level of MyDrive:\", sorted(p.name for p in base.iterdir()))\n",
        "\n",
        "DATA_DIR = base\n",
        "print(\"Using DATA_DIR =\", DATA_DIR)"
      ],
      "metadata": {
        "id": "6KsOtYoWTf8F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb42e97b-ef75-47d4-f7eb-db8f8ca75ee3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-level of MyDrive: ['Colab Notebooks', 'Masters thesis (1).zip', 'PredictionModel (2).ipynb', 'PyRosetta', 'StackingEnsemble (1).ipynb', 'antigens.fasta', 'binding_results', 'data', 'test_neg.txt', 'test_neg_1.txt', 'test_neg_cdrh3.txt', 'test_pos.txt', 'test_pos_1.txt', 'test_pos_cdrh3.txt', 'train_neg (1).gdoc', 'train_neg.gdoc', 'train_neg.txt', 'train_neg_1.txt', 'train_neg_cdrh3.txt', 'train_pos.txt', 'train_pos_1.txt', 'train_pos_cdrh3.txt']\n",
            "Using DATA_DIR = /content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_antigen_sequences(fasta_path):\n",
        "    sequences = {}\n",
        "    with open(fasta_path, \"r\") as f:\n",
        "        for record in SeqIO.parse(f, \"fasta\"):\n",
        "            sequences[record.id] = str(record.seq)\n",
        "    return sequences\n",
        "\n",
        "fasta_path = DATA_DIR/ \"antigens.fasta\"\n",
        "ANTIGEN_SEQUENCES = load_antigen_sequences(fasta_path)\n",
        "\n",
        "print(ANTIGEN_SEQUENCES)"
      ],
      "metadata": {
        "id": "ybudykHxTl6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "270a40dc-99c2-4020-de41-2417568b981c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'SARS-CoV1': 'MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEIFRSDTLYLTQDLFLPFYSNVTGFHTINHTFGNPVIPFKDGIYFAATEKSNVVRGWVFGSTMNNKSQSVIIINNSTNVVIRACNFELCDNPFFAVSKPMGTQTHTMIFDNAFNCTFEYISDAFSLDVSEKSGNFKHLREFVFKNKDGFLYVYKGYQPIDVVRDLPSGFNTLKPIFKLPLGINITNFRAILTAFSPAQDIWGTSAAAYFVGYLKPTTFMLKYDENGTITDAVDCSQNPLAELKCSVKSFEIDKGIYQTSNFRVVPSGDVVRFPNITNLCPFGEVFNATKFPSVYAWERKKISNCVADYSVLYNSTFFSTFKCYGVSATKLNDLCFSNVYADSFVVKGDDVRQIAPGQTGVIADYNYKLPDDFMGCVLAWNTRNIDATSTGNYNYKYRYLRHGKLRPFERDISNVPFSPDGKPCTPPALNCYWPLNDYGFYTTTGIGYQPYRVVVLSFELLNAPATVCGPKLSTDLIKNQCVNFNFNGLTGTGVLTPSSKRFQPFQQFGRDVSDFTDSVRDPKTSEILDISPCSFGGVSVITPGTNASSEVAVLYQDVNCTDVSTAIHADQLTPAWRIYSTGNNVFQTQAGCLIGAEHVDTSYECDIPIGAGICASYHTVSLLRSTSQKSIVAYTMSLGADSSIAYSNNTIAIPTNFSISITTEVMPVSMAKTSVDCNMYICGDSTECANLLLQYGSFCTQLNRALSGIAAEQDRNTREVFAQVKQMYKTPTLKYFGGFNFSQILPDPLKPTKRSFIEDLLFNKVTLADAGFMKQYGECLGDINARDLICAQKFNGLTVLPPLLTDDMIAAYTAALVSGTATAGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKQIANQFNKAISQIQESLTTTSTALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQAAPHGVVFLHVTYVPSQERNFTTAPAICHEGKAYFPREGVFVFNGTSWFITQRNFFSPQIITTDNTFVSGNCDVVIGIINNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYVWLGLFIAGLIAIVMVTILLCCMTSCCSCLKGACSCGSCCKFDEDDSEPVLKGVKLHYT', 'SARS-CoV2': 'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPRRARSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDDSEPVLKGVKLHYT'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AA = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
        "DP = list(product(AA, AA))\n",
        "DP_list = []\n",
        "for i in DP:\n",
        "    DP_list.append(str(i[0]) + str(i[1]))\n",
        "\n",
        "AAindex_list = DP_list.copy()\n",
        "\n",
        "def returnCKSAAPcode(query_seq, k):\n",
        "    code_final = []\n",
        "\n",
        "    for turns in range(k + 1):\n",
        "        DP_dic = {}\n",
        "        code = []\n",
        "        code_order = []\n",
        "        for i in DP_list:\n",
        "            DP_dic[i] = 0\n",
        "        for i in range(len(query_seq) - turns - 1):\n",
        "            tmp_dp_1 = query_seq[i]                # first amino acid\n",
        "            tmp_dp_2 = query_seq[i + turns + 1]    # second amino acid\n",
        "            tmp_dp = tmp_dp_1 + tmp_dp_2           # combine them into a dipeptide string\n",
        "\n",
        "            if tmp_dp in DP_dic.keys():\n",
        "                DP_dic[tmp_dp] += 1\n",
        "            else:\n",
        "                DP_dic[tmp_dp] = 1\n",
        "\n",
        "        for i, j in DP_dic.items():\n",
        "            code.append(j / (len(query_seq) - turns - 1))\n",
        "\n",
        "        for i in AAindex_list:\n",
        "            code_order.append(code[DP_list.index(i)])\n",
        "\n",
        "        code_final += code\n",
        "\n",
        "    return code_final\n",
        "\n",
        "def get_cksaap_length(sample_seq, k):\n",
        "    code = returnCKSAAPcode(sample_seq, k)\n",
        "    return len(code)"
      ],
      "metadata": {
        "id": "8ZP2Gt9gTnjg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tsv_pairs(pos_path, neg_path):\n",
        "    pairs, labels = [], []\n",
        "    for p, lab in [(pos_path, 1), (neg_path, 0)]:\n",
        "        with open(p) as f:\n",
        "            for line in f:\n",
        "                ag_id, heavy, light = line.strip().split(\"\\t\")\n",
        "                pairs.append((ag_id, heavy + light))\n",
        "                labels.append(lab)\n",
        "    return pairs, np.array(labels, dtype=int)"
      ],
      "metadata": {
        "id": "aCk4bbEiqpj2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ──────────────────────────────────────────────\n",
        "# PARAMETERS & DATA LOADING\n",
        "# ──────────────────────────────────────────────\n",
        "print(\"Using DATA_DIR =\", DATA_DIR)\n",
        "\n",
        "OUTPUT_DIR = DATA_DIR / \"binding_results\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "K       = 10\n",
        "PCA_VAR = 0.95\n",
        "CV_FOLDS = 5\n",
        "\n",
        "train_pairs, y_train = load_tsv_pairs(DATA_DIR/\"train_pos.txt\", DATA_DIR/\"train_neg.txt\")\n",
        "test_pairs,  y_test  = load_tsv_pairs(DATA_DIR/\"test_pos.txt\",  DATA_DIR/\"test_neg.txt\")\n",
        "\n",
        "train_seqs = [(ANTIGEN_SEQUENCES[ag], ab) for ag, ab in train_pairs]\n",
        "test_seqs  = [(ANTIGEN_SEQUENCES[ag], ab) for ag, ab in test_pairs]\n",
        "\n",
        "def build_features(pairs, k=K, pca=None):\n",
        "    X = []\n",
        "    for ag, ab in pairs:\n",
        "        c1    = returnCKSAAPcode(ag, k)\n",
        "        c2    = returnCKSAAPcode(ab, k)\n",
        "        diff  = np.abs(np.array(c1) - np.array(c2))\n",
        "        prod  = np.array(c1) * np.array(c2)\n",
        "        X.append(np.concatenate([c1, c2, diff, prod]))\n",
        "    X = np.array(X, dtype=np.float32)\n",
        "    return pca.transform(X) if pca else X\n",
        "\n",
        "t0 = time.time()\n",
        "X_train = build_features(train_seqs)\n",
        "X_test  = build_features(test_seqs)\n",
        "print(f\"Feature building took {time.time() - t0:.2f}s\")\n",
        "joblib.dump((X_train, y_train, X_test, y_test), OUTPUT_DIR/\"features.pkl\")\n",
        "\n",
        "t0 = time.time()\n",
        "pca = PCA(n_components=PCA_VAR, svd_solver='full')\n",
        "pca.fit(X_train)\n",
        "X_train_pca = pca.transform(X_train)\n",
        "X_test_pca  = pca.transform(X_test)\n",
        "print(f\"PCA fit & transform took {time.time() - t0:.2f}s\")\n",
        "joblib.dump(pca, OUTPUT_DIR/\"pca_model.joblib\")\n",
        "\n",
        "LR_PARAM_GRID = {\n",
        "    'clf__C': np.logspace(-3, 3, 7)\n",
        "}\n",
        "\n",
        "RF_PARAM_GRID = {\n",
        "    'n_estimators': [100, 200, 300, 500],\n",
        "    'max_depth': [4, 6, 8, 10],\n",
        "    'min_samples_leaf': [1, 2, 4, 8],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "XGB_PARAM_GRID = {\n",
        "    'n_estimators': [100, 300],\n",
        "    'max_depth': [4, 6],\n",
        "    'learning_rate': [0.001, 0.05, 0.1],\n",
        "}\n",
        "\n",
        "# ──────────────────────────────────────────────\n",
        "# LOGISTIC REGRESSION\n",
        "# ──────────────────────────────────────────────\n",
        "t0 = time.time()\n",
        "lr_pipe = Pipeline([\n",
        "    ('scale', StandardScaler()),\n",
        "    ('clf', LogisticRegression(class_weight='balanced', max_iter=2000))\n",
        "])\n",
        "gs_lr = GridSearchCV(\n",
        "    lr_pipe,\n",
        "    LR_PARAM_GRID,\n",
        "    cv=StratifiedKFold(CV_FOLDS, shuffle=True, random_state=42),\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1\n",
        ")\n",
        "gs_lr.fit(X_train_pca, y_train)\n",
        "lr = gs_lr.best_estimator_\n",
        "print(f\"LR tuning took {time.time() - t0:.2f}s\")\n",
        "joblib.dump(lr, OUTPUT_DIR/\"lr_model.joblib\")\n",
        "\n",
        "# ──────────────────────────────────────────────\n",
        "# RANDOM FOREST\n",
        "# ──────────────────────────────────────────────\n",
        "t0 = time.time()\n",
        "gs_rf = GridSearchCV(\n",
        "    RandomForestClassifier(),\n",
        "    RF_PARAM_GRID,\n",
        "    cv=StratifiedKFold(CV_FOLDS, shuffle=True, random_state=42),\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1\n",
        ")\n",
        "gs_rf.fit(X_train_pca, y_train)\n",
        "rf = gs_rf.best_estimator_\n",
        "print(f\"RF tuning took {time.time() - t0:.2f}s\")\n",
        "joblib.dump(rf, OUTPUT_DIR/\"rf_model.joblib\")\n",
        "\n",
        "# ──────────────────────────────────────────────\n",
        "# XGBOOST\n",
        "# ──────────────────────────────────────────────\n",
        "t0 = time.time()\n",
        "gs_xgb = GridSearchCV(\n",
        "    XGBClassifier(eval_metric='auc'),\n",
        "    XGB_PARAM_GRID,\n",
        "    cv=StratifiedKFold(CV_FOLDS, shuffle=True, random_state=42),\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1\n",
        ")\n",
        "gs_xgb.fit(X_train_pca, y_train)\n",
        "best_xgb = gs_xgb.best_estimator_\n",
        "print(f\"XGBoost tuning took {time.time() - t0:.2f}s\")\n",
        "joblib.dump(best_xgb, OUTPUT_DIR/\"xgb_best.joblib\")\n",
        "\n",
        "# ──────────────────────────────────────────────\n",
        "# STACKING\n",
        "# ──────────────────────────────────────────────\n",
        "t0 = time.time()\n",
        "estimators = [('lr', lr), ('rf', rf), ('xgb', best_xgb)]\n",
        "stack = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=StratifiedKFold(CV_FOLDS, shuffle=True, random_state=42),\n",
        "    n_jobs=-1\n",
        ")\n",
        "stack.fit(X_train_pca, y_train)\n",
        "print(f\"Stacking training took {time.time() - t0:.2f}s\")\n",
        "joblib.dump(stack, OUTPUT_DIR/\"stack_model.joblib\")\n",
        "\n",
        "# ──────────────────────────────────────────────\n",
        "# EVALUATION FUNCTION\n",
        "# ──────────────────────────────────────────────\n",
        "def evaluate(name, model, X, y, prefix):\n",
        "    probs = model.predict_proba(X)[:,1]\n",
        "    preds = (probs >= 0.5).astype(int)\n",
        "    bal   = balanced_accuracy_score(y, preds)\n",
        "    roc   = roc_auc_score(y, probs)\n",
        "    f1    = f1_score(y, preds)\n",
        "    print(f\"{name}: Balanced Acc={bal:.3f}, AUC={roc:.3f}, F1={f1:.3f}\")\n",
        "    print(classification_report(y, preds, digits=3))\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y, probs)\n",
        "    plt.figure(); plt.plot(fpr, tpr, label=f'AUC={roc:.3f}'); plt.plot([0,1],[0,1],'--')\n",
        "    plt.title(f'{name} ROC'); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.legend()\n",
        "    plt.savefig(OUTPUT_DIR/f\"{prefix}_roc.png\", dpi=200); plt.close()\n",
        "\n",
        "    cm = confusion_matrix(y, preds)\n",
        "    plt.figure(figsize=(4,4)); sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'{name} Confusion'); plt.tight_layout()\n",
        "    plt.savefig(OUTPUT_DIR/f\"{prefix}_confusion.png\", dpi=200); plt.close()\n",
        "\n",
        "# ──────────────────────────────────────────────\n",
        "# EVALUATE MODELS\n",
        "# ──────────────────────────────────────────────\n",
        "for nm, mdl in [('lr', lr), ('rf', rf), ('xgb', best_xgb), ('stack', stack)]:\n",
        "    evaluate(nm.upper(), mdl, X_test_pca, y_test, nm)\n",
        "\n",
        "print(\"All done — results and models saved to\", OUTPUT_DIR)"
      ],
      "metadata": {
        "id": "2pSs2wNnNw7q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}