{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77248741-c855-47e8-9459-d60ce156f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, accuracy_score, roc_auc_score, f1_score, roc_curve, auc, precision_recall_curve, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "from Bio import AlignIO, Phylo, SeqIO\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from collections import Counter\n",
    "import time\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f2ad83-e366-4bc3-a8fc-d1086f6b3796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26668e45-c602-4dc3-9286-f23379c0a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0829c-f593-44f3-87f6-7cd823316db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_antigen_sequences(fasta_path):\n",
    "    sequences = {}\n",
    "    with open(fasta_path, \"r\") as f:\n",
    "        for record in SeqIO.parse(f, \"fasta\"):\n",
    "            sequences[record.id] = str(record.seq)\n",
    "    return sequences\n",
    "\n",
    "fasta_path = Path.cwd() / \"antigens.fasta\"\n",
    "ANTIGEN_SEQUENCES = load_antigen_sequences(fasta_path)\n",
    "\n",
    "print(ANTIGEN_SEQUENCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f5e2d3-cf1f-4c09-9e4f-d3ce88577b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(positive_file, negative_file):\n",
    "    \"\"\"\n",
    "    Each line of file:\n",
    "      antigen \\t heavy_chain \\t light_chain\n",
    "    \"\"\"\n",
    "    seq_pairs, labels = [], []\n",
    "\n",
    "    # Read positive file\n",
    "    with open(positive_file, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if len(row) < 3:\n",
    "                continue\n",
    "            antigen = row[0]\n",
    "            antibody = row[1] + row[2]  # heavy + light\n",
    "            seq_pairs.append((antigen, antibody))\n",
    "            labels.append(1.0)\n",
    "\n",
    "    # Read negative file\n",
    "    with open(negative_file, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if len(row) < 3:\n",
    "                continue\n",
    "            antigen = row[0]\n",
    "            antibody = row[1] + row[2]\n",
    "            seq_pairs.append((antigen, antibody))\n",
    "            labels.append(0.0)\n",
    "\n",
    "    return seq_pairs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e140ef8-0566-4d40-9b03-173c24dac3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AA = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "DP = list(product(AA, AA))\n",
    "DP_list = []\n",
    "for i in DP:\n",
    "    DP_list.append(str(i[0]) + str(i[1]))\n",
    "\n",
    "AAindex_list = DP_list.copy()\n",
    "\n",
    "def returnCKSAAPcode(query_seq, k):\n",
    "    code_final = []\n",
    "    for turns in range(k + 1):\n",
    "        \n",
    "        DP_dic = {} \n",
    "        code = []\n",
    "        code_order = []\n",
    "        for i in DP_list:\n",
    "            DP_dic[i] = 0\n",
    "        \n",
    "        for i in range(len(query_seq) - turns - 1):\n",
    "            tmp_dp_1 = query_seq[i]                # first amino acid\n",
    "            tmp_dp_2 = query_seq[i + turns + 1]    # second amino acid\n",
    "            tmp_dp = tmp_dp_1 + tmp_dp_2           # combine them into a dipeptide string\n",
    "            \n",
    "            if tmp_dp in DP_dic.keys():\n",
    "                DP_dic[tmp_dp] += 1\n",
    "            else:\n",
    "                DP_dic[tmp_dp] = 1\n",
    "        \n",
    "        for i, j in DP_dic.items():\n",
    "            code.append(j / (len(query_seq) - turns - 1))\n",
    "        \n",
    "        for i in AAindex_list:\n",
    "            code_order.append(code[DP_list.index(i)])\n",
    "        \n",
    "        code_final += code\n",
    "    \n",
    "    return code_final\n",
    "\n",
    "def get_cksaap_length(sample_seq, k):\n",
    "    code = returnCKSAAPcode(sample_seq, k)\n",
    "    return len(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaff021-894c-4a23-874d-e7023957feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, seq_pairs, labels, k):\n",
    "        self.seq_pairs = seq_pairs\n",
    "        self.labels    = labels\n",
    "        self.k         = k\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq1, seq2 = self.seq_pairs[idx]\n",
    "        if seq1 in ANTIGEN_SEQUENCES:\n",
    "            seq1 = ANTIGEN_SEQUENCES[seq1]\n",
    "\n",
    "        enc_seq1 = returnCKSAAPcode(seq1, self.k)\n",
    "        enc_seq2 = returnCKSAAPcode(seq2, self.k)\n",
    "\n",
    "        return (\n",
    "            torch.tensor(enc_seq1, dtype=torch.float32),\n",
    "            torch.tensor(enc_seq2, dtype=torch.float32),\n",
    "            torch.tensor(self.labels[idx], dtype=torch.long)   # ← HERE\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ade70-7077-48d1-81de-c845b65d454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        c,h,w = input_shape\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(c, 10, 3, 1), nn.BatchNorm2d(10), nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(10,20,3,1),   nn.BatchNorm2d(20), nn.LeakyReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, c, h, w)\n",
    "            flat  = self.cnn(dummy).shape[1]\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(flat*4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):   return self.cnn(x)\n",
    "    def forward(self, x1, x2):\n",
    "        o1 = self.forward_once(x1)\n",
    "        o2 = self.forward_once(x2)\n",
    "        diff = torch.abs(o1 - o2)\n",
    "        prod = o1 * o2\n",
    "        return self.fc(torch.cat([o1, o2, diff, prod], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56301d73-6f86-4dc0-872d-1297baaaba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CWD:\", os.getcwd())\n",
    "\n",
    "print(\"Contents:\", os.listdir())\n",
    "\n",
    "sub = \"AbAgIntPre/CoV-AbDab\"\n",
    "if os.path.isdir(sub):\n",
    "    print(f\"\\nContents of {sub}:\", os.listdir(sub))\n",
    "else:\n",
    "    print(f\"\\nNo folder named {sub} here.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee1976-f365-45bb-826c-dd372db704e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The collate_fn function customizes how individual samples are combined into a batch.\n",
    "# It performs the following steps:\n",
    "# 1. Unpacks the batch (a list of tuples) into separate lists for seq1, seq2, and labels.\n",
    "# 2. Reshapes each sequence tensor from its original shape (e.g., (L,)) into the expected CNN input shape (channels, height, width).\n",
    "# 3. Uses torch.stack to combine the individual tensors into a single batch tensor.\n",
    "#    - torch.stack takes a list of tensors (all of the same shape) and stacks them along a new dimension,\n",
    "#      resulting in a tensor of shape (batch_size, ...).\n",
    "def get_collate_fn(input_shape):\n",
    "    def collate_fn(batch):\n",
    "        seq1_list, seq2_list, label_list = zip(*batch)\n",
    "        seq1_tensor = torch.stack([x.view(input_shape) for x in seq1_list])\n",
    "        seq2_tensor = torch.stack([x.view(input_shape) for x in seq2_list])\n",
    "        labels_tensor = torch.stack(label_list)\n",
    "        return seq1_tensor, seq2_tensor, labels_tensor\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b6a28-d5ca-489f-a9b8-efec8a7e9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        c, h, w = input_shape\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(c, 10, 3, 1), nn.BatchNorm2d(10), nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(10, 20, 3, 1), nn.BatchNorm2d(20), nn.LeakyReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, c, h, w)\n",
    "            flat = self.cnn(dummy).shape[1]\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(flat * 4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        o1 = self.forward_once(x1)\n",
    "        o2 = self.forward_once(x2)\n",
    "        diff = torch.abs(o1 - o2)\n",
    "        prod = o1 * o2\n",
    "        return self.fc(torch.cat([o1, o2, diff, prod], dim=1))\n",
    "\n",
    "\n",
    "def plot_roc_curves(roc_data, title=None):\n",
    "    plt.figure()\n",
    "    for i, (fpr, tpr, fold_auc) in enumerate(roc_data, 1):\n",
    "        plt.plot(fpr, tpr, label=f\"Fold {i} (AUC={fold_auc:.3f})\")\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", linewidth=1)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_pr_curves(pr_data, title=None):\n",
    "    plt.figure()\n",
    "    for i, (prec, rec, pr_auc) in enumerate(pr_data, 1):\n",
    "        plt.plot(rec, prec, label=f\"Fold {i} (AUC={pr_auc:.3f})\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def cross_validate_model(seq_pairs, labels, k=4, folds=5,\n",
    "                         epochs=50, bs=32, lr=1e-3, patience=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_shape = (k + 1, 20, 20)\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "    best_aucs = []\n",
    "    roc_data = []\n",
    "    pr_data = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(seq_pairs, labels), 1):\n",
    "        print(f\"\\n=== Fold {fold}/{folds} ===\")\n",
    "        train_ds = SequenceDataset([seq_pairs[i] for i in train_idx],\n",
    "                                   [labels[i] for i in train_idx], k)\n",
    "        val_ds   = SequenceDataset([seq_pairs[i] for i in val_idx],\n",
    "                                   [labels[i] for i in val_idx], k)\n",
    "        collate = get_collate_fn(input_shape)\n",
    "        tr_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, collate_fn=collate)\n",
    "        val_loader = DataLoader(val_ds, batch_size=bs, shuffle=False, collate_fn=collate)\n",
    "\n",
    "        model = SiameseNetwork(input_shape).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max',\n",
    "                                                         factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "        best_auc = 0.0\n",
    "        wait = 0\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            model.train()\n",
    "            for x1, x2, y in tr_loader:\n",
    "                x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(x1, x2)\n",
    "                loss = criterion(logits, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            all_y, all_p = [], []\n",
    "            with torch.no_grad():\n",
    "                for x1, x2, y in val_loader:\n",
    "                    x1, x2 = x1.to(device), x2.to(device)\n",
    "                    logits = model(x1, x2)\n",
    "                    probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "                    all_p.extend(probs.cpu().tolist())\n",
    "                    all_y.extend(y.tolist())\n",
    "\n",
    "            fold_auc = roc_auc_score(all_y, all_p)\n",
    "            scheduler.step(fold_auc)\n",
    "            print(f\"Epoch {epoch}: Val AUC = {fold_auc:.4f}  LR = {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "            # Early stopping logic\n",
    "            if fold_auc > best_auc:\n",
    "                best_auc = fold_auc\n",
    "                wait = 0\n",
    "                torch.save(model.state_dict(), f\"best_fold{fold}.pth\")\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= patience:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "\n",
    "        model.load_state_dict(torch.load(f\"best_fold{fold}.pth\"))\n",
    "        model.eval()\n",
    "        all_y, all_p = [], []\n",
    "        with torch.no_grad():\n",
    "            for x1, x2, y in val_loader:\n",
    "                x1, x2 = x1.to(device), x2.to(device)\n",
    "                logits = model(x1, x2)\n",
    "                probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "                all_p.extend(probs.cpu().tolist())\n",
    "                all_y.extend(y.tolist())\n",
    "\n",
    "        best_aucs.append(best_auc)\n",
    "        fpr, tpr, _ = roc_curve(all_y, all_p)\n",
    "        roc_data.append((fpr, tpr, best_auc))\n",
    "        prec, rec, _ = precision_recall_curve(all_y, all_p)\n",
    "        pr_auc = auc(rec, prec)\n",
    "        pr_data.append((prec, rec, pr_auc))\n",
    "\n",
    "    mean_auc = np.mean(best_aucs)\n",
    "    std_auc = np.std(best_aucs)\n",
    "    print(f\"\\n>>> Mean CV AUC = {mean_auc:.3f} ± {std_auc:.3f}\")\n",
    "\n",
    "    return best_aucs, roc_data, pr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127605c7-f430-4d23-98f1-bacfd819403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(cm, title, out_path, classes=['Neg','Pos']):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "    plt.title(f\"{title} Confusion\")\n",
    "    plt.colorbar()\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, cm[i,j], ha='center', va='center',\n",
    "                     color='white' if cm[i,j] > cm.max()/2 else 'black')\n",
    "    plt.xticks([0,1], classes)\n",
    "    plt.yticks([0,1], classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_roc(fpr, tpr, roc_auc, title, out_path):\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    ax.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\", linewidth=2)\n",
    "    ax.plot([0,1],[0,1],'--', color='orange', linewidth=2)\n",
    "    ax.set_xlabel(\"FPR\")\n",
    "    ax.set_ylabel(\"TPR\")\n",
    "    ax.set_title(f\"{title} ROC\")\n",
    "    ax.legend(loc='upper left', frameon=True, fontsize='small')\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "OUTPUT_DIR = Path.cwd() / \"final_model_outputs\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "k = 4\n",
    "input_shape = (k+1, 20, 20)\n",
    "bs = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_epochs = 30\n",
    "lr = 1e-4\n",
    "\n",
    "train_pos_file = Path.cwd() / \"AbAgIntPre\" / \"CoV-AbDab\" / \"train_pos.txt\"\n",
    "train_neg_file = Path.cwd() / \"AbAgIntPre\" / \"CoV-AbDab\" / \"train_neg.txt\"\n",
    "test_pos_file  = Path.cwd() / \"AbAgIntPre\" / \"CoV-AbDab\" / \"test_pos.txt\"\n",
    "test_neg_file  = Path.cwd() / \"AbAgIntPre\" / \"CoV-AbDab\" / \"test_neg.txt\"\n",
    "\n",
    "seq_pairs_train, train_labels = load_data(train_pos_file, train_neg_file)\n",
    "seq_pairs_test,  test_labels  = load_data(test_pos_file,  test_neg_file)\n",
    "\n",
    "train_ds = SequenceDataset(seq_pairs_train, train_labels, k)\n",
    "test_ds  = SequenceDataset(seq_pairs_test,  test_labels,  k)\n",
    "\n",
    "collate = get_collate_fn(input_shape)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=bs,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=bs,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate\n",
    ")\n",
    "\n",
    "\n",
    "model     = SiameseNetwork(input_shape).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"Training on {len(train_ds)} examples for {n_epochs} epochs…\")\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for x1, x2, y in train_loader:\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x1, x2)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * y.size(0)\n",
    "\n",
    "    avg_loss = running_loss / len(train_ds)\n",
    "    print(f\"Epoch {epoch:02d}  loss={avg_loss:.4f}  time={(time.time()-t0):.1f}s\")\n",
    "\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_probs  = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x1, x2, y in test_loader:\n",
    "        x1, x2 = x1.to(device), x2.to(device)\n",
    "        logits = model(x1, x2)\n",
    "        probs = torch.softmax(logits, dim=1)[:,1].cpu().numpy()\n",
    "        all_probs.extend(probs)\n",
    "        all_labels.extend(y.numpy())\n",
    "\n",
    "all_preds = (np.array(all_probs) >= 0.5).astype(int)\n",
    "\n",
    "test_bal_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "test_roc_auc  = roc_auc_score(all_labels, all_probs)\n",
    "print(f\"\\nTest balanced acc: {test_bal_acc:.3f}   ROC-AUC: {test_roc_auc:.3f}\")\n",
    "print(classification_report(all_labels, all_preds, digits=3))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plot_confusion(cm, title=\"Siamese AbAgIntPre ROC\", out_path=OUTPUT_DIR/\"test_confusion.png\")\n",
    "\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "plot_roc(fpr, tpr, test_roc_auc, title=\"Siamese AbAgIntPre ROC\", out_path=OUTPUT_DIR/\"test_roc.png\")\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(f\"Siamese Confusion\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR/ f\"Siamese_confusion.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "plt.figure(); plt.plot(fpr, tpr, label=f'AUC={test_roc_auc:.3f}'); plt.plot([0,1],[0,1],'--');\n",
    "plt.title(f'Siamese AbAgIntPre ROC'); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.legend();\n",
    "plt.savefig(OUTPUT_DIR/f\"siamese_roc.png\", dpi=200); plt.close()\n",
    "\n",
    "print(f\"\\nSaved test_confusion.png and test_roc.png in {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb7b5b-aa75-4ac9-9203-1a202d8a9ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
