{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0307d49c-add8-4966-b27d-99895ccc246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, classification_report, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, accuracy_score, roc_auc_score, f1_score, roc_curve, auc, precision_recall_curve, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "from Bio import SeqIO\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import csv\n",
    "import os\n",
    "import subprocess\n",
    "import random\n",
    "from Bio import AlignIO, Phylo, SeqIO\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from Bio import SeqIO\n",
    "import csv\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e299efe7-a38e-4ec5-97b1-9eb9b0279039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3831c912-4a10-4238-ac56-dd061d6eb354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6df7e2bb-8349-4e9a-a4db-82b4fa676e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SARS-CoV1': 'MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEIFRSDTLYLTQDLFLPFYSNVTGFHTINHTFGNPVIPFKDGIYFAATEKSNVVRGWVFGSTMNNKSQSVIIINNSTNVVIRACNFELCDNPFFAVSKPMGTQTHTMIFDNAFNCTFEYISDAFSLDVSEKSGNFKHLREFVFKNKDGFLYVYKGYQPIDVVRDLPSGFNTLKPIFKLPLGINITNFRAILTAFSPAQDIWGTSAAAYFVGYLKPTTFMLKYDENGTITDAVDCSQNPLAELKCSVKSFEIDKGIYQTSNFRVVPSGDVVRFPNITNLCPFGEVFNATKFPSVYAWERKKISNCVADYSVLYNSTFFSTFKCYGVSATKLNDLCFSNVYADSFVVKGDDVRQIAPGQTGVIADYNYKLPDDFMGCVLAWNTRNIDATSTGNYNYKYRYLRHGKLRPFERDISNVPFSPDGKPCTPPALNCYWPLNDYGFYTTTGIGYQPYRVVVLSFELLNAPATVCGPKLSTDLIKNQCVNFNFNGLTGTGVLTPSSKRFQPFQQFGRDVSDFTDSVRDPKTSEILDISPCSFGGVSVITPGTNASSEVAVLYQDVNCTDVSTAIHADQLTPAWRIYSTGNNVFQTQAGCLIGAEHVDTSYECDIPIGAGICASYHTVSLLRSTSQKSIVAYTMSLGADSSIAYSNNTIAIPTNFSISITTEVMPVSMAKTSVDCNMYICGDSTECANLLLQYGSFCTQLNRALSGIAAEQDRNTREVFAQVKQMYKTPTLKYFGGFNFSQILPDPLKPTKRSFIEDLLFNKVTLADAGFMKQYGECLGDINARDLICAQKFNGLTVLPPLLTDDMIAAYTAALVSGTATAGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKQIANQFNKAISQIQESLTTTSTALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQAAPHGVVFLHVTYVPSQERNFTTAPAICHEGKAYFPREGVFVFNGTSWFITQRNFFSPQIITTDNTFVSGNCDVVIGIINNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYVWLGLFIAGLIAIVMVTILLCCMTSCCSCLKGACSCGSCCKFDEDDSEPVLKGVKLHYT', 'SARS-CoV2': 'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPRRARSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDDSEPVLKGVKLHYT'}\n"
     ]
    }
   ],
   "source": [
    "def load_antigen_sequences(fasta_path):\n",
    "    sequences = {}\n",
    "    with open(fasta_path, \"r\") as f:\n",
    "        for record in SeqIO.parse(f, \"fasta\"):\n",
    "            sequences[record.id] = str(record.seq)\n",
    "    return sequences\n",
    "\n",
    "fasta_path = Path.cwd() / \"antigens.fasta\"\n",
    "ANTIGEN_SEQUENCES = load_antigen_sequences(fasta_path)\n",
    "\n",
    "print(ANTIGEN_SEQUENCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17d2d7ed-8de9-4a8f-9fdd-3528b3323e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequence_pairs(positive_file, negative_file):\n",
    "    seq_pairs = []\n",
    "    labels = []\n",
    "\n",
    "    with open(positive_file, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if len(row) < 3:\n",
    "                continue\n",
    "            antigen_id = row[0].strip()\n",
    "            heavy = row[1].strip()\n",
    "            light = row[2].strip()\n",
    "\n",
    "            # Lookup the antigen sequence\n",
    "            antigen_seq = ANTIGEN_SEQUENCES.get(antigen_id)\n",
    "            if antigen_seq is None:\n",
    "                continue\n",
    "\n",
    "            antibody_seq = heavy + light\n",
    "\n",
    "            # Append merged (antigen, antibody) pair\n",
    "            seq_pairs.append((antigen_seq, antibody_seq))\n",
    "            labels.append(1.0)\n",
    "\n",
    "    with open(negative_file, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if len(row) < 3:\n",
    "                continue\n",
    "            antigen_id = row[0].strip()\n",
    "            heavy = row[1].strip()\n",
    "            light = row[2].strip()\n",
    "\n",
    "            antigen_seq = ANTIGEN_SEQUENCES.get(antigen_id)\n",
    "            if antigen_seq is None:\n",
    "                continue\n",
    "\n",
    "            antibody_seq = heavy + light\n",
    "\n",
    "            seq_pairs.append((antigen_seq, antibody_seq))\n",
    "            labels.append(0.0)\n",
    "\n",
    "    return seq_pairs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a347d14a-141e-4f54-84a2-7007c4a39587",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMINO_ACIDS = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "AA_TO_INDEX = {aa: idx for idx, aa in enumerate(AMINO_ACIDS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ecfc5e6e-4230-459c-840b-a26837d3b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotSequenceDataset(Dataset):\n",
    "    def __init__(self, seq_pairs, labels):\n",
    "        self.seq_pairs = seq_pairs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq1, seq2 = self.seq_pairs[idx]\n",
    "\n",
    "        if seq1 in globals().get(\"ANTIGEN_SEQUENCES\", {}):\n",
    "            seq1 = ANTIGEN_SEQUENCES[seq1]\n",
    "\n",
    "        merged_seq = seq1 + seq2\n",
    "\n",
    "        enc_seq = one_hot_encode(merged_seq)  # (seq_len, 20)\n",
    "\n",
    "        return (\n",
    "            torch.tensor(enc_seq, dtype=torch.float32),  # (seq_len, 20)\n",
    "            torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e511848-ba38-43b6-90a8-1e7e87abf78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size=20, hidden_size=128, num_layers=1):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        out = out[:, -1, :] \n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c2294ca-17a6-4802-9eae-aaa6a139a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0.0)\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    return padded_sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd207b-6707-4404-ad66-d66cc2cb4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "AMINO_ACIDS  = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "AA_TO_INDEX  = {aa:i for i,aa in enumerate(AMINO_ACIDS)}\n",
    "\n",
    "def clean_sequence(seq: str) -> str:\n",
    "    return \"\".join([aa for aa in seq if aa in AA_TO_INDEX])\n",
    "\n",
    "def one_hot_encode(seq: str) -> np.ndarray:\n",
    "    L = len(seq)\n",
    "    mat = np.zeros((L, len(AMINO_ACIDS)), dtype=np.float32)\n",
    "    for i, aa in enumerate(seq):\n",
    "        mat[i, AA_TO_INDEX[aa]] = 1.0\n",
    "    return mat\n",
    "\n",
    "class OneHotSequenceDataset(Dataset):\n",
    "    def __init__(self, seq_pairs, labels, antigen_dict):\n",
    "        self.seq_pairs    = seq_pairs\n",
    "        self.labels       = labels\n",
    "        self.antigen_dict = antigen_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ag_id, ab_seq = self.seq_pairs[idx]\n",
    "        ag_seq = self.antigen_dict[ag_id]\n",
    "        merged = clean_sequence(ag_seq) + clean_sequence(ab_seq)\n",
    "        oh     = one_hot_encode(merged)\n",
    "        return torch.tensor(oh), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "def load_antigen_sequences(fasta_path: Path):\n",
    "    d = {}\n",
    "    for rec in SeqIO.parse(str(fasta_path), \"fasta\"):\n",
    "        d[rec.id] = str(rec.seq)\n",
    "    return d\n",
    "\n",
    "def load_sequence_pairs(pos_path: Path, neg_path: Path):\n",
    "    pairs, labels = [], []\n",
    "    for path, label in [(pos_path, 1.0), (neg_path, 0.0)]:\n",
    "        with open(path, newline=\"\") as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\")\n",
    "            for row in reader:\n",
    "                if len(row) >= 3:\n",
    "                    ag_id = row[0].strip()\n",
    "                    heavy = row[1].strip()\n",
    "                    light = row[2].strip()\n",
    "                    pairs.append((ag_id, heavy + light))\n",
    "                    labels.append(label)\n",
    "    return pairs, labels\n",
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size=20, hidden_size=128, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers,\n",
    "            batch_first=True, bidirectional=True, dropout=dropout\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        last   = out[:, -1, :]\n",
    "        last   = self.dropout(last)\n",
    "        return self.fc(last).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de710de5-65e0-4c23-bb71-81f173392529",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    WORKDIR      = Path.cwd()\n",
    "    antigen_fasta= WORKDIR / \"antigens.fasta\"\n",
    "    TRAIN_POS    = WORKDIR / \"AbAgIntPre/CoV-AbDab/train_pos.txt\"\n",
    "    TRAIN_NEG    = WORKDIR / \"AbAgIntPre/CoV-AbDab/train_neg.txt\"\n",
    "    TEST_POS     = WORKDIR / \"AbAgIntPre/CoV-AbDab/test_pos.txt\"\n",
    "    TEST_NEG     = WORKDIR / \"AbAgIntPre/CoV-AbDab/test_neg.txt\"\n",
    "\n",
    "    antigen_dict = load_antigen_sequences(antigen_fasta)\n",
    "\n",
    "    seq_pairs, labels = load_sequence_pairs(TRAIN_POS, TRAIN_NEG)\n",
    "    print(f\"Total train+val samples: {len(seq_pairs)}\")\n",
    "    full_ds = OneHotSequenceDataset(seq_pairs, labels, antigen_dict)\n",
    "\n",
    "    n_train = int(0.9 * len(full_ds))\n",
    "    n_val   = len(full_ds) - n_train\n",
    "    train_ds, val_ds = random_split(full_ds, [n_train, n_val])\n",
    "    print(f\" Train: {len(train_ds)}, Val: {len(val_ds)}\")\n",
    "\n",
    "    # test\n",
    "    test_pairs, test_labels = load_sequence_pairs(TEST_POS, TEST_NEG)\n",
    "    test_ds = OneHotSequenceDataset(test_pairs, test_labels, antigen_dict)\n",
    "    print(f\" Test: {len(test_ds)}\")\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  collate_fn=collate_batch)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, collate_fn=collate_batch)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "\n",
    "    model     = BiLSTMClassifier().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "\n",
    "    num_epochs    = 100\n",
    "    best_val_loss = float('inf')\n",
    "    patience      = 10\n",
    "    wait          = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_batch)\n",
    "            loss   = criterion(logits, y_batch)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # val\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in val_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                val_loss += criterion(model(x_batch), y_batch).item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{num_epochs} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\")\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_bilstm_model.pth\")\n",
    "            print(\" â†³ Saved best model\")\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"No improvement for {patience} epochs, stopping.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_bilstm_model.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            all_logits.append(model(x_batch).cpu())\n",
    "            all_labels.append(y_batch.cpu())\n",
    "    logits = torch.cat(all_logits)\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_prob = torch.sigmoid(logits).numpy()\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    auc     = roc_auc_score(y_true, y_prob)\n",
    "    report  = classification_report(y_true, y_pred, digits=3)\n",
    "    cm      = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(\"\\n=== TEST SET PERFORMANCE ===\")\n",
    "    print(f\"Balanced Accuracy: {bal_acc:.3f}\")\n",
    "    print(f\"AUC:               {auc:.3f}\")\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c4fcc7a-8861-4d61-b2bc-c4cbc2ca4c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr, roc_auc, name, out_path):\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    \n",
    "    ax.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\", linewidth=2)\n",
    "    ax.plot([0,1], [0,1], '--', color='orange', linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel(\"FPR\")\n",
    "    ax.set_ylabel(\"TPR\")\n",
    "    ax.set_title(f\"{name} ROC\")\n",
    "    \n",
    "    ax.legend(loc='upper left', fontsize='small', frameon=True)\n",
    "\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def evaluate_torch(name, model, data_loader, device, output_dir):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            logits  = model(x_batch)\n",
    "            probs   = torch.sigmoid(logits).cpu().numpy().ravel()\n",
    "            preds   = (probs >= 0.5).astype(int)\n",
    "\n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(y_batch.cpu().numpy().astype(int))\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    bal_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "    roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "    report  = classification_report(all_labels, all_preds, digits=3)\n",
    "    cm      = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(f\"\\n--- {name} Evaluation ---\")\n",
    "    print(f\"Predict time: {elapsed:.3f}s\")\n",
    "    print(f\"Balanced Acc: {bal_acc:.3f}    ROC-AUC: {roc_auc:.3f}\")\n",
    "    print(report)\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"{name} Confusion\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f\"{name}_confusion.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "    plt.figure(); plt.plot(fpr, tpr, label=f'AUC={roc_auc:.3f}'); plt.plot([0,1],[0,1],'--');\n",
    "    plt.title(f'{name} ROC'); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.legend();\n",
    "    plt.savefig(OUTPUT_DIR/f\"bilstm_roc.png\", dpi=200); plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db7abd-e6ec-4927-a9b7-fa7947d4c656",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb4b42-606c-4114-8000-6f3b3fbbc0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = WORKDIR / \"outputs\"\n",
    "evaluate_torch(\n",
    "    name=\"BiLSTM\",\n",
    "    model=model,\n",
    "    data_loader=val_loader,\n",
    "    device=device,\n",
    "    output_dir=OUTPUT_DIR\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
