{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407009c-ee97-4127-96a1-d079f248a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import csv\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from Bio import SeqIO\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274a2a4d-ad78-4520-ab69-92d73a167610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SARS-CoV1': 'MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEIFRSDTLYLTQDLFLPFYSNVTGFHTINHTFGNPVIPFKDGIYFAATEKSNVVRGWVFGSTMNNKSQSVIIINNSTNVVIRACNFELCDNPFFAVSKPMGTQTHTMIFDNAFNCTFEYISDAFSLDVSEKSGNFKHLREFVFKNKDGFLYVYKGYQPIDVVRDLPSGFNTLKPIFKLPLGINITNFRAILTAFSPAQDIWGTSAAAYFVGYLKPTTFMLKYDENGTITDAVDCSQNPLAELKCSVKSFEIDKGIYQTSNFRVVPSGDVVRFPNITNLCPFGEVFNATKFPSVYAWERKKISNCVADYSVLYNSTFFSTFKCYGVSATKLNDLCFSNVYADSFVVKGDDVRQIAPGQTGVIADYNYKLPDDFMGCVLAWNTRNIDATSTGNYNYKYRYLRHGKLRPFERDISNVPFSPDGKPCTPPALNCYWPLNDYGFYTTTGIGYQPYRVVVLSFELLNAPATVCGPKLSTDLIKNQCVNFNFNGLTGTGVLTPSSKRFQPFQQFGRDVSDFTDSVRDPKTSEILDISPCSFGGVSVITPGTNASSEVAVLYQDVNCTDVSTAIHADQLTPAWRIYSTGNNVFQTQAGCLIGAEHVDTSYECDIPIGAGICASYHTVSLLRSTSQKSIVAYTMSLGADSSIAYSNNTIAIPTNFSISITTEVMPVSMAKTSVDCNMYICGDSTECANLLLQYGSFCTQLNRALSGIAAEQDRNTREVFAQVKQMYKTPTLKYFGGFNFSQILPDPLKPTKRSFIEDLLFNKVTLADAGFMKQYGECLGDINARDLICAQKFNGLTVLPPLLTDDMIAAYTAALVSGTATAGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKQIANQFNKAISQIQESLTTTSTALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQAAPHGVVFLHVTYVPSQERNFTTAPAICHEGKAYFPREGVFVFNGTSWFITQRNFFSPQIITTDNTFVSGNCDVVIGIINNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYVWLGLFIAGLIAIVMVTILLCCMTSCCSCLKGACSCGSCCKFDEDDSEPVLKGVKLHYT', 'SARS-CoV2': 'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPRRARSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDDSEPVLKGVKLHYT'}\n"
     ]
    }
   ],
   "source": [
    "def load_antigen_sequences(fasta_path):\n",
    "    sequences = {}\n",
    "    with open(fasta_path, \"r\") as f:\n",
    "        for record in SeqIO.parse(f, \"fasta\"):\n",
    "            sequences[record.id] = str(record.seq)\n",
    "    return sequences\n",
    "\n",
    "fasta_path = Path.cwd() / \"antigens.fasta\"\n",
    "ANTIGEN_SEQUENCES = load_antigen_sequences(fasta_path)\n",
    "\n",
    "print(ANTIGEN_SEQUENCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42f5fa7-64b6-4762-8c5c-f211c56c1a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Desktop\\MastersYear3-Thesis\\PredictiveModelAntibodyAntigen\n",
      "Loaded 8058 total pairs\n",
      "Running CD-HIT: wsl cd-hit -i /mnt/c/Users/franc/Desktop/MastersYear3-Thesis/PredictiveModelAntibodyAntigen/AbAgIntPre/CoV-AbDab/pairs.fasta -o /mnt/c/Users/franc/Desktop/MastersYear3-Thesis/PredictiveModelAntibodyAntigen/AbAgIntPre/CoV-AbDab/pairs_nr98.fasta -c 0.70 -n 4 -M 0 -T 4\n",
      "Cluster-balanced down to 8058 pairs\n",
      "Class-balanced to 1428 pairs (714 pos + 714 neg)\n",
      "Final splits → train: 1285, test: 143\n",
      "Wrote train/test files:\n",
      "  C:\\Users\\franc\\Desktop\\MastersYear3-Thesis\\PredictiveModelAntibodyAntigen\\AbAgIntPre\\CoV-AbDab\\train_pos.txt, C:\\Users\\franc\\Desktop\\MastersYear3-Thesis\\PredictiveModelAntibodyAntigen\\AbAgIntPre\\CoV-AbDab\\train_neg.txt\n",
      "  C:\\Users\\franc\\Desktop\\MastersYear3-Thesis\\PredictiveModelAntibodyAntigen\\AbAgIntPre\\CoV-AbDab\\test_pos.txt,  C:\\Users\\franc\\Desktop\\MastersYear3-Thesis\\PredictiveModelAntibodyAntigen\\AbAgIntPre\\CoV-AbDab\\test_neg.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import csv\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from Bio import SeqIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# =======================\n",
    "# USER-ADJUSTABLE PARAMETERS\n",
    "# =======================\n",
    "# - Set WORKDIR to your working directory (default: current dir)\n",
    "# - Set IDENTITY_CUTOFF and USE_CDHIT for CD-HIT clustering.\n",
    "# - Set TEST_SIZE for train/test split proportion.\n",
    "# - Set filter_substr to filter antigen IDs (None for all IDs).\n",
    "WORKDIR = Path.cwd()\n",
    "ANTIGEN_FASTA = WORKDIR / \"antigens.fasta\"\n",
    "POS_TSV = WORKDIR / \"AbAgIntPre\" / \"CoV-AbDab\" / \"positive dataset.txt\"\n",
    "NEG_TSV = WORKDIR / \"AbAgIntPre\" / \"CoV-AbDab\" / \"negative dataset.txt\"\n",
    "PAIR_FASTA = WORKDIR / \"AbAgIntPre\" / \"CoV-AbDab\" / \"pairs.fasta\"\n",
    "CDHIT_OUT = WORKDIR / \"AbAgIntPre\" / \"CoV-AbDab\" / \"pairs_nr98.fasta\"\n",
    "POS_OUT = WORKDIR / \"AbAgIntPre\" / \"CoV-AbDab\" / \"positive_balanced.txt\"\n",
    "NEG_OUT = WORKDIR / \"AbAgIntPre\" / \"CoV-AbDab\" / \"negative_balanced.txt\"\n",
    "TRAIN_POS = WORKDIR / \"AbAgIntPre\" / \"CoV-AbDab\" / \"train_pos.txt\"\n",
    "TRAIN_NEG = WORKDIR / \"AbAgIntPre\" / \"CoV-AbDab\" / \"train_neg.txt\"\n",
    "TEST_POS = WORKDIR / \"AbAgIntPre\" / \"CoV-AbDab\" / \"test_pos.txt\"\n",
    "TEST_NEG = WORKDIR / \"AbAgIntPre\" / \"CoV-AbDab\" / \"test_neg.txt\"\n",
    "\n",
    "IDENTITY_CUTOFF  = 0.7\n",
    "CDHIT_THREADS    = 4\n",
    "TEST_SIZE        = 0.10 \n",
    "\n",
    "# Set this to a substring of the antigen IDs you want to include,\n",
    "# or None to include all.\n",
    "filter_substr = 'SARS-CoV2'\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Optional CD-HIT step\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Set USE_CDHIT = False if you want to skip clustering and use raw pairs\n",
    "USE_CDHIT = False\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Utility: convert Windows path to WSL mount path\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def win_to_wsl(win_path):\n",
    "    abspath = os.path.abspath(win_path)\n",
    "    drive, rest = os.path.splitdrive(abspath)\n",
    "    letter = drive.rstrip(\":\").lower()\n",
    "    rest = rest.replace(\"\\\\\", \"/\").lstrip(\"/\")\n",
    "    return f\"/mnt/{letter}/{rest}\"\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Load antigen sequences from FASTA into a dict: ID → sequence\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "ANTIGEN_SEQS = {\n",
    "    record.id: str(record.seq)\n",
    "    for record in SeqIO.parse(ANTIGEN_FASTA, \"fasta\")\n",
    "}\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Read original triplets TSV, look up antigen sequence by ID\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def load_triplets(pos_file, neg_file, filter_substr=None):\n",
    "    trips = []\n",
    "    for fn, label in [(pos_file, 1), (neg_file, 0)]:\n",
    "        with open(fn) as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\")\n",
    "            for row in reader:\n",
    "                if len(row) < 3:\n",
    "                    continue\n",
    "                ag_id, heavy, light = row[0].strip(), row[1].strip(), row[2].strip()\n",
    "                if filter_substr and filter_substr not in ag_id:\n",
    "                    continue\n",
    "                ag_seq = ANTIGEN_SEQS.get(ag_id)\n",
    "                if ag_seq is None or len(ag_seq) < 50:\n",
    "                    continue\n",
    "                trips.append((ag_id, ag_seq, heavy, light, label))\n",
    "    return trips\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Write concatenated antigen+heavy+light FASTA for CD-HIT\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def write_pair_fasta(trips, fasta_path):\n",
    "    with open(fasta_path, \"w\") as fa:\n",
    "        for i, (_ag_id, ag_seq, heavy, light, _) in enumerate(trips):\n",
    "            seq = ag_seq + heavy + light\n",
    "            fa.write(f\">Pair{i}\\n{seq}\\n\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Run CD-HIT on concatenated sequences\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def run_cdhit(in_fa, out_fa, identity, threads):\n",
    "    word_size = 5 if identity >= 0.90 else 4\n",
    "    cmd = [\n",
    "        \"cd-hit\",\n",
    "        \"-i\", win_to_wsl(in_fa),\n",
    "        \"-o\", win_to_wsl(out_fa),\n",
    "        \"-c\", f\"{identity:.2f}\",\n",
    "        \"-n\", str(word_size),\n",
    "        \"-M\", \"0\",\n",
    "        \"-T\", str(threads),\n",
    "    ]\n",
    "    if os.name == \"nt\":\n",
    "        cmd.insert(0, \"wsl\")\n",
    "    print(\"Running CD-HIT:\", \" \".join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Parse the .clstr file to map PairID → clusterID\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def parse_pair_clusters(clstr_path):\n",
    "    cluster_of = {}\n",
    "    curr = None\n",
    "    with open(clstr_path) as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\">Cluster\"):\n",
    "                curr = int(line.split()[1])\n",
    "            else:\n",
    "                parts = line.split(\">\")\n",
    "                if len(parts) > 1:\n",
    "                    pid = parts[1].split(\"...\")[0]\n",
    "                    cluster_of[pid] = curr\n",
    "    return cluster_of\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Balance so each CD-HIT cluster contributes equally\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def balance_by_cluster(trips, cluster_of):\n",
    "    by_cluster = defaultdict(list)\n",
    "    for idx, trip in enumerate(trips):\n",
    "        pid = f\"Pair{idx}\"\n",
    "        cid = cluster_of.get(pid)\n",
    "        by_cluster[cid].append(trip)\n",
    "    target = min(len(group) for group in by_cluster.values())\n",
    "    balanced = []\n",
    "    for group in by_cluster.values():\n",
    "        balanced.extend(random.sample(group, target))\n",
    "    random.shuffle(balanced)\n",
    "    return balanced\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Write out positive vs negative TSV (using antigen IDs)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def write_output(trips, pos_path, neg_path):\n",
    "    with open(pos_path, \"w\") as p, open(neg_path, \"w\") as n:\n",
    "        for ag_id, _ag_seq, heavy, light, label in trips:\n",
    "            line = f\"{ag_id}\\t{heavy}\\t{light}\\n\"\n",
    "            (p if label == 1 else n).write(line)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Main\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    os.chdir(WORKDIR)\n",
    "\n",
    "    all_trips = load_triplets(POS_TSV, NEG_TSV, filter_substr)\n",
    "    print(f\"Loaded {len(all_trips)} total pairs\")\n",
    "\n",
    "    if USE_CDHIT:\n",
    "        write_pair_fasta(all_trips, PAIR_FASTA)\n",
    "        run_cdhit(PAIR_FASTA, CDHIT_OUT, IDENTITY_CUTOFF, CDHIT_THREADS)\n",
    "        clusters = parse_pair_clusters(f\"{CDHIT_OUT}.clstr\")\n",
    "        balanced_clusters = balance_by_cluster(all_trips, clusters)\n",
    "        print(f\"Cluster-balanced down to {len(balanced_clusters)} pairs\")\n",
    "        write_output(balanced_clusters, POS_OUT, NEG_OUT)\n",
    "    else:\n",
    "        balanced_clusters = all_trips\n",
    "        print(f\"Skipping CD-HIT. Proceeding with {len(balanced_clusters)} raw pairs.\")\n",
    "\n",
    "    # Class-level 1:1 pos/neg balancing\n",
    "    positives = [t for t in balanced_clusters if t[4] == 1]\n",
    "    negatives = [t for t in balanced_clusters if t[4] == 0]\n",
    "    cls_target = min(len(positives), len(negatives))\n",
    "    positives_ds = random.sample(positives, cls_target)\n",
    "    negatives_ds = random.sample(negatives, cls_target)\n",
    "    balanced_class = positives_ds + negatives_ds\n",
    "    random.shuffle(balanced_class)\n",
    "    print(f\"Class-balanced to {len(balanced_class)} pairs ({cls_target} pos + {cls_target} neg)\")\n",
    "    write_output(balanced_class, POS_OUT, NEG_OUT)\n",
    "\n",
    "    # Stratified split into train/test only (80/20 by label)\n",
    "    labels = [t[4] for t in balanced_class]\n",
    "    train, test = train_test_split(\n",
    "        balanced_class,\n",
    "        test_size=TEST_SIZE,\n",
    "        stratify=labels,\n",
    "        random_state=42\n",
    "    )\n",
    "    print(f\"Final splits → train: {len(train)}, test: {len(test)}\")\n",
    "\n",
    "    # Write train/test pos & neg\n",
    "    write_output(train, TRAIN_POS, TRAIN_NEG)\n",
    "    write_output(test,  TEST_POS,  TEST_NEG)\n",
    "    print(\"Wrote train/test files:\")\n",
    "    print(f\"  {TRAIN_POS}, {TRAIN_NEG}\")\n",
    "    print(f\"  {TEST_POS},  {TEST_NEG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6769f33-6433-4422-bdde-ae8ffeb5c67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
