{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f15ee69-b62e-4ce3-874d-f257857bc72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from Bio import SeqIO\n",
    "from io import StringIO\n",
    "\n",
    "INPUT_CSV = \"files.csv\"  \n",
    "OUTPUT_CSV = \"output.csv\" \n",
    "FASTA_FOLDER = \"fastas\"   \n",
    "\n",
    "def get_all_urls(cell_value):\n",
    "    \"\"\"\n",
    "    Splits a cell that may contain multiple URLs separated by semicolons (or commas, spaces).\n",
    "    Returns a list of cleaned URLs (stripped of whitespace and trailing semicolons).\n",
    "    \"\"\"\n",
    "    # Split by semicolons or whitespace. You can add commas if needed:\n",
    "    # re.split(r'[;\\s,]+', cell_value.strip())\n",
    "    parts = re.split(r'[;\\s]+', cell_value.strip())\n",
    "    \n",
    "    # Remove empty strings and trailing punctuation\n",
    "    urls = []\n",
    "    for part in parts:\n",
    "        cleaned = part.strip().rstrip(\";\").rstrip(\",\").rstrip(\"/\")\n",
    "        # Keep only if it starts with 'http' (basic check for a valid URL)\n",
    "        if cleaned.startswith(\"http\"):\n",
    "            urls.append(cleaned)\n",
    "    return urls\n",
    "\n",
    "def extract_pdb_id_from_url(url):\n",
    "    \"\"\"\n",
    "    Extract the PDB ID from an RCSB structure URL.\n",
    "    Example: 'https://www.rcsb.org/structure/7DJZ' -> '7DJZ'\n",
    "    \"\"\"\n",
    "    # After stripping trailing slashes, take the last part\n",
    "    return url.split(\"/\")[-1]\n",
    "\n",
    "def download_fasta(pdb_id):\n",
    "    \"\"\"\n",
    "    Download the FASTA for a given PDB ID from RCSB.\n",
    "    Returns the FASTA text or None if there is an error.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.rcsb.org/fasta/entry/{pdb_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"Error retrieving {pdb_id}: HTTP {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def parse_fasta_for_chains(fasta_text):\n",
    "    \"\"\"\n",
    "    Parse the FASTA text and separate sequences into heavy_chains and light_chains.\n",
    "    Returns two lists: [sequences for heavy], [sequences for light].\n",
    "    \"\"\"\n",
    "    heavy_chains = []\n",
    "    light_chains = []\n",
    "    \n",
    "    fasta_io = StringIO(fasta_text)\n",
    "    for record in SeqIO.parse(fasta_io, \"fasta\"):\n",
    "        header = record.description.lower()\n",
    "        seq_str = str(record.seq)\n",
    "        \n",
    "        if \"heavy\" in header or \"h chain\" in header:\n",
    "            heavy_chains.append(seq_str)\n",
    "        elif \"light\" in header or \"l chain\" in header:\n",
    "            light_chains.append(seq_str)\n",
    "        # else: not obviously heavy or light\n",
    "    \n",
    "    return heavy_chains, light_chains\n",
    "\n",
    "def main():\n",
    "    # 1. Create the FASTA folder if it doesn't exist\n",
    "    if not os.path.exists(FASTA_FOLDER):\n",
    "        os.makedirs(FASTA_FOLDER)\n",
    "    \n",
    "    output_rows = []\n",
    "    \n",
    "    with open(INPUT_CSV, \"r\", newline=\"\", encoding=\"utf-8\") as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        \n",
    "        # If your CSV has a header row, read it\n",
    "        header = next(reader, None)  # comment out if you have no header\n",
    "        \n",
    "        for row in reader:\n",
    "            # We assume:\n",
    "            #   row[0] = CloneName\n",
    "            #   row[1] = BindsTo\n",
    "            #   row[2] = cell containing one or more URLs\n",
    "            if len(row) < 3:\n",
    "                continue\n",
    "            \n",
    "            clone_name = row[0].strip()\n",
    "            binds_to   = row[1].strip()\n",
    "            cell_with_urls = row[2].strip()\n",
    "            \n",
    "            # Get *all* URLs from the cell\n",
    "            urls = get_all_urls(cell_with_urls)\n",
    "            \n",
    "            # Prepare lists to collect sequences across all URLs\n",
    "            all_heavy_sequences = []\n",
    "            all_light_sequences = []\n",
    "            \n",
    "            # Download and parse each URLâ€™s FASTA\n",
    "            for url in urls:\n",
    "                pdb_id = extract_pdb_id_from_url(url)\n",
    "                fasta_text = download_fasta(pdb_id)\n",
    "                \n",
    "                if fasta_text:\n",
    "                    # Save FASTA to disk\n",
    "                    fasta_filename = os.path.join(FASTA_FOLDER, f\"{pdb_id}.fasta\")\n",
    "                    with open(fasta_filename, \"w\", encoding=\"utf-8\") as f_out:\n",
    "                        f_out.write(fasta_text)\n",
    "                    \n",
    "                    # Parse for heavy/light sequences\n",
    "                    heavy_list, light_list = parse_fasta_for_chains(fasta_text)\n",
    "                    \n",
    "                    # Add them to our master lists\n",
    "                    all_heavy_sequences.extend(heavy_list)\n",
    "                    all_light_sequences.extend(light_list)\n",
    "                else:\n",
    "                    # Could not download for this URL; skip\n",
    "                    pass\n",
    "            \n",
    "            # Combine all sequences found\n",
    "            heavy_seq_str = \";\".join(all_heavy_sequences)\n",
    "            light_seq_str = \";\".join(all_light_sequences)\n",
    "            \n",
    "            # Count them\n",
    "            heavy_count = len(all_heavy_sequences)\n",
    "            light_count = len(all_light_sequences)\n",
    "            \n",
    "            # Store the row in our output\n",
    "            output_rows.append({\n",
    "                \"CloneName\": clone_name,\n",
    "                \"BindsTo\": binds_to,\n",
    "                \"AllURLs\": cell_with_urls,             # Keep the original text of all URLs\n",
    "                \"HeavyChainCount\": heavy_count,\n",
    "                \"LightChainCount\": light_count,\n",
    "                \"HeavyChainSequences\": heavy_seq_str,\n",
    "                \"LightChainSequences\": light_seq_str\n",
    "            })\n",
    "    \n",
    "    # Write results to a new CSV\n",
    "    fieldnames = [\n",
    "        \"CloneName\",\n",
    "        \"BindsTo\",\n",
    "        \"AllURLs\",\n",
    "        \"HeavyChainCount\",\n",
    "        \"LightChainCount\",\n",
    "        \"HeavyChainSequences\",\n",
    "        \"LightChainSequences\"\n",
    "    ]\n",
    "    \n",
    "    with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for out_row in output_rows:\n",
    "            writer.writerow(out_row)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
